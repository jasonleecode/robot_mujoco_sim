import torch
import torch.nn as nn

# === 1. å®šä¹‰æ¨¡å‹ç»“æ„ (ä»æºç å¤åˆ»å¹¶ç®€åŒ–) ===
class ActorCritic(nn.Module):
    def __init__(self, 
                 num_obs=48,              # æœºå™¨äººå½“å‰çŠ¶æ€ç»´åº¦
                 num_privileged_obs=48,   # è®­ç»ƒæ—¶çš„ä½œå¼Šä¿¡æ¯ (æ¨ç†æ—¶ä¸éœ€è¦ï¼Œä½†ä¸ºäº†åŠ è½½æƒé‡å¾—å ä½)
                 num_obs_history=30*48,   # å†å²è§‚æµ‹ (å…³é”®è¾“å…¥!)
                 num_actions=12):         # 12ä¸ªç”µæœº
        super().__init__()

        # --- é…ç½®å‚æ•° (æ¥è‡ªåŸä»£ç  AC_Args) ---
        actor_hidden_dims = [512, 256, 128]
        critic_hidden_dims = [512, 256, 128]
        activation = nn.ELU()
        
        # é€‚åº”æ€§æ¨¡å—å‚æ•° (Adaptation Module)
        # è¾“å…¥: å†å²æ•°æ® -> è¾“å‡º: éšå˜é‡ (Latent)
        adaptation_branch_hidden_dims = [256, 32] 
        latent_dim = 18  # env_factor_encoder_branch_latent_dims

        # --- A. é€‚åº”æ€§æ¨¡å— (Student çš„ç›´è§‰) ---
        # è´Ÿè´£ä»å†å²æ•°æ®ä¸­â€œçŒœâ€å‡ºåœ°å½¢ä¿¡æ¯
        adaptation_layers = []
        adaptation_layers.append(nn.Linear(num_obs_history, adaptation_branch_hidden_dims[0]))
        adaptation_layers.append(activation)
        adaptation_layers.append(nn.Linear(adaptation_branch_hidden_dims[0], adaptation_branch_hidden_dims[1])) # 32
        # æ³¨æ„ï¼šåŸä»£ç é€»è¾‘é‡Œï¼Œæœ€åä¸€å±‚è¾“å‡ºçš„æ˜¯ latent_dim (18)
        # è¿™é‡Œéœ€è¦ä»”ç»†å¯¹é½åŸä»£ç çš„å¾ªç¯é€»è¾‘:
        # if l == len(branch_hidden_dims) - 1: linear(..., branch_latent_dim)
        adaptation_layers.append(nn.Linear(adaptation_branch_hidden_dims[1], latent_dim)) 
        self.adaptation_module = nn.Sequential(*adaptation_layers)

        # --- B. ç­–ç•¥ç½‘ç»œ (Actor Body) ---
        # è´Ÿè´£æ ¹æ® (å½“å‰çŠ¶æ€ + çŒœæµ‹çš„åœ°å½¢) è¾“å‡ºåŠ¨ä½œ
        actor_layers = []
        # è¾“å…¥æ˜¯: å½“å‰çŠ¶æ€(num_obs) + éšå˜é‡(latent_dim)
        actor_layers.append(nn.Linear(num_obs + latent_dim, actor_hidden_dims[0]))
        actor_layers.append(activation)
        for i in range(len(actor_hidden_dims) - 1):
            actor_layers.append(nn.Linear(actor_hidden_dims[i], actor_hidden_dims[i+1]))
            actor_layers.append(activation)
        actor_layers.append(nn.Linear(actor_hidden_dims[-1], num_actions))
        self.actor_body = nn.Sequential(*actor_layers)

        # --- C. å ä½æ¨¡å— (ä¸ºäº†é˜²æ­¢ load_state_dict æŠ¥é”™) ---
        # ç¯å¢ƒç¼–ç å™¨ (Teacher)
        self.env_factor_encoder = nn.Sequential(
            nn.Linear(18, 256), activation, # å‡è®¾è¾“å…¥æ˜¯18
            nn.Linear(256, 128), activation,
            nn.Linear(128, 18)
        )
        # ä»·å€¼ç½‘ç»œ (Critic)
        self.critic_body = nn.Sequential(nn.Linear(num_obs+latent_dim, 1))
        
        # åŠ¨ä½œæ ‡å‡†å·® (RL è®­ç»ƒå‚æ•°)
        self.std = nn.Parameter(torch.ones(num_actions))

    def forward(self, obs, obs_history):
        """
        æ¨ç†æ—¶çš„å‰å‘ä¼ æ’­ (Student Mode)
        Args:
            obs: å½“å‰æ—¶åˆ»çš„è§‚æµ‹ [Batch, num_obs]
            obs_history: å†å²è§‚æµ‹ [Batch, num_obs_history]
        """
        # 1. ç”¨å†å²æ•°æ®çŒœ Latent
        latent = self.adaptation_module(obs_history)
        
        # 2. æ‹¼æ¥ å½“å‰çŠ¶æ€ + Latent
        input_vec = torch.cat((obs, latent), dim=-1)
        
        # 3. è¾“å‡ºåŠ¨ä½œ
        actions = self.actor_body(input_vec)
        return actions

# === 2. åŠ è½½ä¸æµ‹è¯•å‡½æ•° ===
def load_and_run(pt_path):
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½: {pt_path}")
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(pt_path, map_location='cpu')
    state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint

    # --- è‡ªåŠ¨æ¢æµ‹ç»´åº¦ (é‡è¦!) ---
    # å°è¯•ä»æƒé‡ä¸­æ¨æ–­ input sizeï¼Œé˜²æ­¢ config ä¸åŒ¹é…
    try:
        # adaptation_module.0.weight çš„ shape æ˜¯ [256, input_dim]
        hist_input_dim = state_dict['adaptation_module.0.weight'].shape[1]
        print(f"ğŸ•µï¸ æ¢æµ‹åˆ°å†å²è¾“å…¥ç»´åº¦ (History Dim): {hist_input_dim}")
        
        # actor_body.0.weight çš„ shape æ˜¯ [512, obs_dim + latent_dim]
        # æˆ‘ä»¬å·²çŸ¥ latent_dim é€šå¸¸æ˜¯ 18 (æˆ–è€… 16/32)
        # è¿™é‡Œå‡è®¾ latent_dim = 18 (æ ¹æ®åŸä»£ç  default)
        actor_first_layer_dim = state_dict['actor_body.0.weight'].shape[1]
        obs_dim = actor_first_layer_dim - 18 
        print(f"ğŸ•µï¸ æ¢æµ‹åˆ°è§‚æµ‹ç»´åº¦ (Obs Dim): {obs_dim}")
        
    except KeyError:
        print("âš ï¸ æ— æ³•è‡ªåŠ¨æ¢æµ‹ç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼...")
        hist_input_dim = 30 * 48 # å‡è®¾
        obs_dim = 48

    # å®ä¾‹åŒ–æ¨¡å‹
    model = ActorCritic(num_obs=obs_dim, num_obs_history=hist_input_dim)
    
    # åŠ è½½æƒé‡ (ä½¿ç”¨ strict=False å¿½ç•¥æ‰ä¸åŒ¹é…çš„å±‚ï¼Œæ¯”å¦‚ critic ç»“æ„å¯èƒ½æœ‰ç»†å¾®å·®å¼‚)
    try:
        model.load_state_dict(state_dict, strict=False)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    # --- æ¨¡æ‹Ÿæ¨ç† ---
    # æ„é€ å‡æ•°æ®
    dummy_obs = torch.randn(1, obs_dim)
    dummy_history = torch.randn(1, hist_input_dim)
    
    with torch.no_grad():
        action = model(dummy_obs, dummy_history)
        
    print("\nğŸ‰ æ¨ç†æˆåŠŸï¼")
    print(f"è¾“å…¥ Obs å½¢çŠ¶: {dummy_obs.shape}")
    print(f"è¾“å…¥ History å½¢çŠ¶: {dummy_history.shape}")
    print(f"è¾“å‡º Action å½¢çŠ¶: {action.shape}")
    print("è¾“å‡ºå€¼ç¤ºä¾‹:", action[0][:4].numpy(), "...")

if __name__ == "__main__":
    # æ›¿æ¢æˆä½ çš„ .pt æ–‡ä»¶è·¯å¾„
    load_and_run("unitree_go1.pt")